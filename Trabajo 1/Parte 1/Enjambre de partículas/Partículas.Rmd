---
title: "Partículas"
author: "SebastianSotoAr"
date: "2025-06-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(pso)
library(purrr)
library(tibble)
library(ggplot2)
```

## Función de Rosenbrock

### Definición de dos variables

```{r}
f_rosenbrock_2d <- function(x, y) {   
  f_value <- 100*(y-(x^2))^2 + ((1-x)^2)   
  return(f_value) 
}  
```

### Definición de tres variables

```{r}
f_rosenbrock_3d <- function(x, y, z) {   
  f_value <- 100*((y-x^2)^2 + (z-y^2)^2) + (1-x)^2 + (1-y)^2
  return(f_value) 
}
```

### Definición multidimencional

```{r}
f_rosenbrock <- function(x){
  x_1 <- tail(x, -1)
  x <- head(x, -1)
  z <- sum((100*((x_1-(x^2))^2))+((1-x)^2))
  return(z)
}
```

## Función de Rastrigin

### Definición de dos variables

```{r}
f_rastrigin_2d <- function(x, y) {
  A = 10   
  f_value <- x^2 + y^2 + A*(2 - cos(2*pi*x) - cos(2*pi*y))   
  return(f_value) 
}  
```

### Definición de tres variables

```{r}
f_rastrigin_3d <- function(x, y, z) {   
  A = 10   
  f_value <- x^2 + y^2 + z^2 + A*(3 - cos(2*pi*x) - cos(2*pi*y) - cos(2*pi*z))   
  return(f_value) 
}
```

### Definición multidimencional

```{r}
f_rastrigin <-function(x){
  A <- 10
  n <- length(x)
  z <- (A*n) + sum(x^2 - A*cos(2*pi*x))
  return(z)
}
```

## 1.5 Método de optimización de partículas

El método de optimización por enjambre de partículas (PSO, por sus siglas en inglés) es un algoritmo inspirado en el comportamiento colectivo de animales como bandadas de aves o bancos de peces. Funciona mediante un conjunto de partículas (soluciones potenciales) que exploran el espacio de búsqueda moviéndose en función de su propia experiencia y la de sus vecinas. Cada partícula ajusta su posición y velocidad iterativamente para acercarse a la mejor solución conocida, guiada por su mejor posición histórica y la mejor posición global encontrada por el enjambre. Con el tiempo, las partículas tienden a converger hacia una solución óptima o cercana al óptimo.

### 1.5.1 Implementación en R de optimización de partículas

Se utiliza el paquete pos para implementar el método de la optimización de partículas. Adicionalmente, se implementa una función adicional para crear las animaciones del método de optimización.

```{r}
list_to_matrix <- function(data) {
  for (i in 1:length(data)) {
    data[[i]] <- matrix(data[[i]], nrow=2, ncol=12)
  }
  return(data)
}

particle_swarm_optimization <- function(n,func,lower_bounds,upper_bounds) {
  set.seed(2001)
  o_min <- psoptim(rep(NA,n), func, lower=lower_bounds,upper=upper_bounds,control=list(fnscale=1e-8,trace=1,trace.stats=TRUE))
  o_max <- psoptim(rep(NA,n), func, lower=lower_bounds,upper=upper_bounds,control=list(fnscale=-1*(1e-8),trace=1,trace.stats=TRUE,s=30))
  print("=====================SUMMARY=====================")
  print("MINIMIZATION:")
  print("Point:")
  show(o_min$par)
  print("Value:")
  show(func(o_min$par))
  print("MAXIMIZATION")
  print("Point:")
  show(o_max$par)
  print("Value:")
  show(func(o_max$par))
  return(list("o_min"=o_min, "o_max"=o_max))
}

animate_pso <- function(particles_positions, func, gif_name) {
  positions_per_iteration <- list_to_matrix(particles_positions)
  df <- map2_dfr(
    positions_per_iteration,
    .y = seq_along(positions_per_iteration),
    .f = function(mat, iter) {
      tibble(
        particle_id = 1:ncol(mat),
        x = mat[1, ],
        y = mat[2, ],
        iter = iter
      )
    }
  )
  x_seq <- seq(-10, 10, length.out = 100)
  y_seq <- seq(-10, 10, length.out = 100)
  grid <- expand.grid(x = x_seq, y = y_seq)
  grid$z <- with(grid, func(x, y))
  
  p <- ggplot() +
    geom_contour(data = grid, aes(x=x, y=y, z=z),
                 bins = 30, color = "gray") +
    geom_point(data=df, aes(x = x, y = y), color="red", size=2) +
    xlim(-10, 10) + ylim(-10, 10) +  # Adjust limits to your data range
    theme_minimal() +
    transition_manual(frames = iter) +
    labs(title = "Iteration: {current_frame}")
  #p + transition_reveal(agno)
  animate(p, fps = 5, renderer=gifski_renderer())
  anim_save(gif_name,p)
}
```

### 1.5.2 Optimización de la función de Rosenbrock en 2 dimensiones

```{r}
# Parámetros a utilizar
n <- 2
lower_bounds <- -20
upper_bounds <- 20

# Ejecución del método
o_pso <- particle_swarm_optimization(n,f_rosenbrock,lower_bounds,upper_bounds)

```

```{r}
# Graficación del proceso de optimización (minimización)
o_min <- o_pso$o_min
o_min_particles_positions <- o_min$stats$x
gif_name <- "pso_rosenbrock_min.gif"
animate_pso(o_min_particles_positions, f_rosenbrock_2d, gif_name)
```

![](images/pso_rosenbrock_min-01.gif)

```{r}
# Graficación del proceso de optimización (maximización)
o_max <- o_pso$o_max
o_max_particles_positions <- o_max$stats$x
gif_name <- "pso_rosenbrock_max.gif"
animate_pso(o_max_particles_positions, f_rosenbrock_2d, gif_name)
```

![](images/pso_rosenbrock_max-01.gif)

### 1.5.3 Optimización de la función de Rosenbrock en 3 dimensiones

```{r}
# Parámetros a utilizar
n <- 3
lower_bounds <- -5
upped_bounds <- 5

# Ejecución del método
o_pso <- particle_swarm_optimization(n,f_rosenbrock,lower_bounds,upper_bounds)
# Graficación del proceso de optimización
```

### 1.5.4 Optimización de la función de Rastrigin en 2 dimensiones

```{r}
# Parámetros a utilizar
n <- 2
lower_bounds <- -5
upped_bounds <- 5

# Ejecución del método
o_pso <- particle_swarm_optimization(n,f_rastrigin,lower_bounds,upper_bounds)
```

```{r}
# Graficación del proceso de optimización (minimización)
o_min <- o_pso$o_min
o_min_particles_positions <- o_min$stats$x
gif_name <- "pso_rastrigin_min.gif"
animate_pso(o_min_particles_positions, f_rastrigin_2d, gif_name)
```

![](images/pso_rastrigin_min.gif)

```{r}
# Graficación del proceso de optimización (maximización)
o_max <- o_pso$o_max
o_max_particles_positions <- o_max$stats$x
gif_name <- "pso_rastrigin_max.gif"
animate_pso(o_max_particles_positions, f_rastrigin_2d, gif_name)
```

![](images/pso_rastrigin_max.gif)

### 1.5.5 Optimización de la función de Rastrigin en 3 dimensiones

```{r}
# Parámetros a utilizar
n <- 3
lower_bounds <- -5
upped_bounds <- 5
# Ejecución del método
o_pso <- particle_swarm_optimization(n,f_rastrigin,lower_bounds,upper_bounds)
```

### 1.5.6 Conclusiones método de optimización de partículas

En el caso de la optimización maximizando las funciones, llegan muy rápido a una solución óptima (dentro de 10 iteraciones). Por otro lado, la optimización minimizando las funciones tardaba un poco más en llegar al óptimo, pero se acercaba mucho al mínimo global.

Estos resultados pueden deberse a la distribución de las partículas por el espacio de búsqueda, permitiendo una optimización más "abierta" a comparación con el método de descenso de gradiente.

## 1.6 Método de algoritmos evolutivos

Los algoritmos genéticos (AG) son técnicas de búsqueda heurística basadas en procesos de evolución natural​ . En un AG típico se define una función FITNESS que evalúa la calidad de cada solución candidata (individuo). A partir de una población inicial aleatoria, se iteran ciclos donde se seleccionan individuos más aptos, se combinan sus “genes” mediante cruces (crossover) y se introducen modificaciones aleatorias (mutaciones). Estos operadores evolucionan la población hacia regiones con mejor fitness.

Según (Scrucca, 2013), los GAs han sido exitosos en optimizar funciones continuas (diferenciables o no) y discretas. Entre los operadores genéticos clave se destacan:

-   Selección: elige individuos con mayor fitness para reproducirse, imitando la supervivencia del más apto.

-   Cruce (crossover): combina partes de dos soluciones parentales para generar descendencia, explorando nuevas regiones del espacio de búsqueda.

-   Mutación: altera aleatoriamente parte de un individuo (por ejemplo, cambiando un valor de su vector de variables) para introducir diversidad genética y evitar estancamiento en óptimos locales.

Los algoritmos genéticos (AG) son metaheurísticas inspiradas en procesos evolutivos biológicos, que han demostrado eficacia en la búsqueda global de óptimos en funciones complejas​jstatsoft.org Los AG simulan la selección natural, la recombinación (cruce) y la mutación para iterativamente mejorar un conjunto de soluciones candidatas (población). Estas técnicas estocásticas son adecuadas para funciones no lineales, discontinuas o con múltiples óptimos locales donde los métodos basados en derivadas pueden fallar. Para evaluar la robustez de los GA, se realizarán múltiples ejecuciones independientes y se analizará la dispersión del fitness resultante.

Adicionalmente, se definen algunas funciones para poder mostrar por medio de una animación el proceso de optimización para las funciones de Rosenbrock y de Rastrigin.

```{r}
animate_ga_optimization <- function(func) {
  # 1. Crear el entorno para almacenar la evolución de la población
  pop_data <- data.frame()
  
  # 2. Ejecutar el algoritmo genético, capturando las poblaciones
  ga_rastrigin <- ga(
    type = "real-valued",
    fitness = function(x) -func(x),
    lower = c(-5.12, -5.12), upper = c(5.12, 5.12),
    popSize = 50, maxiter = 50, run = 50,
    monitor = function(obj) {
      gen <- obj@iter
      pop <- obj@population
      df <- data.frame(
        X1 = pop[, 1],
        X2 = pop[, 2],
        Generacion = gen
      )
      pop_data <<- rbind(pop_data, df)
    }
  )
  
  # 3. Crear grilla para visualizar la función Rastrigin
  x <- seq(-5.12, 5.12, length.out = 100)
  y <- seq(-5.12, 5.12, length.out = 100)
  grid <- expand.grid(X1 = x, X2 = y)
  grid$Z <- apply(grid, 1, func)
  
  # 4. Graficar y animar
  base_plot <- ggplot() +
    geom_raster(data = grid, aes(x = X1, y = X2, fill = Z), interpolate = TRUE) +
    scale_fill_viridis_c() +
    geom_point(data = pop_data, aes(x = X1, y = X2), color = "red", size = 1, alpha = 0.6) +
    labs(title = "Optimización de Rastrigin usando GA", subtitle = "Generación: {closest_state}",
         x = "x1", y = "x2") +
    transition_states(Generacion, transition_length = 2, state_length = 1) +
    theme_minimal()
  
  # 5. Exportar como GIF
  anim_save("optim_rastrigin_ga.gif", animation = animate(base_plot, renderer = gifski_renderer(), fps = 5, width = 600, height = 500))
}

```

Analizaremos cada función en 2 y 3 dimensiones, graficando su paisaje antes de la optimización y luego aplicando un AG con múltiples corridas para evaluar la robustez de los resultados.

### 1.6.1 Implementación en R de algoritmos evolutivos

Se utiliza la función ga() del paquete GA. Para problemas de minimización se define la función de fitness como el negativo del valor objetivo, ya que ga() maximiza por defecto. Se especifican los límites de búsqueda.

Los resúmenes en cada ejecución reportan el mejor fitness encontrado (negativo) y la solución óptima en cada ejecución.

### 1.6.2 Optimización de la función de Rosenbrock en 2 dimensiones

```{r}
# Ejecución del método
ga_ros2d <- ga(type = "real-valued",
               fitness = function(x) -f_rosenbrock(x),
               lower = c(-5, -5), upper = c(5, 5),
               popSize = 50, maxiter = 100, run = 50)
summary(ga_ros2d)
```

```{r}
# Graficación del proceso de optimización
gif_name <- "optim_rosenbrock_ga.gif"
animate_ga_optimization(f_rosenbrock)
```

![](images/optim_rastrigin_ga.gif)

```{r}
set.seed(123)  # semilla reproducible
best_vals_ros <- replicate(30, {
  GA <- ga(type = "real-valued",
           fitness = function(x) -f_rosenbrock(x),
           lower = c(-5, -5), upper = c(5, 5),
           popSize = 50, maxiter = 100, run = 50)
  -GA@fitnessValue  # convertir a valor positivo
})
mean_ros <- mean(best_vals_ros)
sd_ros   <- sd(best_vals_ros)
```

### 1.6.3 Optimización de la función de Rosenbrock en 3 dimensiones

```{r}
# Ejecución del método
ga_ros3d <- ga(type = "real-valued",
               fitness = function(x) -f_rosenbrock(x),
               lower = c(-5, -5, 3), upper = c(5, 5, 3),
               popSize = 50, maxiter = 100, run = 50)
summary(ga_ros3d)
```

```{r}
# Realizar 30 ejecuciones independientes para Rosenbrock 3D
set.seed(123)  # semilla reproducible
best_vals_ros3d <- replicate(30, {
  GA <- ga(type = "real-valued",
           fitness = function(x) -f_rosenbrock(x),
           lower = c(-5, -5, 3), upper = c(5, 5, 3),
           popSize = 50, maxiter = 100, run = 50)
  -GA@fitnessValue  # convertir a valor positivo
})
mean_ros3d <- mean(best_vals_ros3d)
sd_ros3d   <- sd(best_vals_ros3d)
#  Rosenbrock 3D, Rastrigin 3D.
```

### 1.6.4 Optimización de la función de Rastrigin en 2 dimensiones

```{r}
# Ejecución del método
ga_ras2d <- ga(type = "real-valued",
               fitness = function(x) -f_rastrigin(x),
               lower = c(-5, -12), upper = c(5, 12),
               popSize = 50, maxiter = 100, run = 50)
summary(ga_ras2d)

```

```{r}
# Graficación del proceso de optimización
gif_name <- "optim_rastrigin_ga.gif"
animate_ga_optimization(f_rastrigin)
```

![](images/optim_rastrigin_ga-01.gif)

```{r}
set.seed(123)  # semilla reproducible
best_vals_ras2d <- replicate(30, {
  GA <- ga(type = "real-valued",
           fitness = function(x) -f_rastrigin(x),
           lower = c(-5, -5), upper = c(5, 5),
           popSize = 50, maxiter = 100, run = 50)
  -GA@fitnessValue  # convertir a valor positivo
})
mean_ras2d <- mean(best_vals_ras2d)
sd_ras2d   <- sd(best_vals_ras2d)
```

### 1.6.5 Optimización de la función de Rastrigin en 3 dimensiones

```{r}
# Ejecución del método
ga_ras3d <- ga(type = "real-valued",
               fitness = function(x) -f_rastrigin(x),
               lower = c(-5, -12,3), upper = c(5, 12,3 ),
               popSize = 50, maxiter = 100, run = 50)
summary(ga_ras3d)
```

```{r}
set.seed(123)  # semilla reproducible
best_vals_ras3d <- replicate(30, {
  GA <- ga(type = "real-valued",
           fitness = function(x) -f_rastrigin(x),
           lower = c(-5, -5, 3), upper = c(5, 5, 3),
           popSize = 50, maxiter = 100, run = 50)
  -GA@fitnessValue  # convertir a valor positivo
})
mean_ras3d <- mean(best_vals_ras3d)
sd_ras3d   <- sd(best_vals_ras3d)
```

### 1.6.6 Cálculo de estadísticas y análisis

Para evaluar la variabilidad del método estocástico, se repite cada caso al menos 30 veces con semillas distintas. Se registra el mejor valor de fitness (valorizado positivamente) obtenido en cada corrida. Se calcularán estadísticas (media y desviación estándar) del mejor valor de fitness obtenido en 30 ejecuciones independientes de cada caso y se resumirán en una tabla.

Con los vectores de mejores valores (best_vals_ros, etc.), se calculan la media y desviación estándar de cada conjunto de 30 resultados. Por ejemplo, mean_ros y sd_ros arriba y las demas, Para asi presentar los resultados.

```{r}
library(knitr)
resultados <- data.frame(
  Función   = c("Rosenbrock", "Rastrigin", "Rosenbrock", "Rastrigin"),
  Dimensión = c("2D", "2D", "3D", "3D"),
  Media     = c(mean_ros, mean_ras2d, mean_ros3d, mean_ras3d),
  SD        = c(sd_ros, sd_ras2d, sd_ros3d, sd_ras3d)
)
kable(resultados, caption = "Resumen estadístico (media y desviación estándar) del mejor fitness obtenido tras 30 ejecuciones independientes de cada caso.")

```

Los resultados de las múltiples ejecuciones se resumen en la Tabla 1. Esta tabla muestra la media y desviación estándar del mejor valor de fitness (recordado que es el valor de la función objetivo en su mínimo global, típicamente cercano a 0) para cada combinación de función y dimensión. Se observa que para Rosenbrock 2D, la media del fitness mínimo es cercana a 0 con baja dispersión, reflejando que el GA normalmente encuentra el mínimo global (0) o cercano. Para Rastrigin 2D, la media también puede acercarse a 0, pero con mayor desviación estándar debido a los múltiples mínimos locales. En 3D ambos problemas suelen mostrar valores medios mayores (más alejados de 0) y mayor variabilidad, lo cual indica una mayor dificultad de búsqueda al aumentar la dimensionalidad.

```{r}
# tabla de los valores calculados)
library(knitr)
res_df <- data.frame(
  Función   = c("Rosenbrock", "Rastrigin", "Rosenbrock", "Rastrigin"),
  Dimensión = c("2D", "2D", "3D", "3D"),
  Media     = c(mean_ros, mean_ras2d, mean_ros3d, mean_ras3d),
  SD        = c(sd_ros, sd_ras2d, sd_ros3d, sd_ras3d)
)
kable(res_df, caption = "Tabla 1. Estadísticas (media y desviación estándar) del fitness mínimo alcanzado en 30 corridas independientes para cada función y dimensión.")

```

**Tabla 1.** Estadísticas (media y desviación estándar) del fitness mínimo alcanzado en 30 corridas independientes para cada función y dimensión.

### 1.6.7 Conclusiones método de algoritmos evolutivos

Los resultados confirman que el algoritmo genético es capaz de aproximarse a los mínimos globales de ambos problemas en múltiples dimensiones. Como era de esperar, Rastrigin mostró mayor variabilidad en los valores de fitness debido a sus muchos mínimos locales, lo que implica que algunas ejecuciones del GA pueden quedarse atrapadas en óptimos locales alejados del global. En contraste, Rosenbrock (aunque es no convexa) tiende a un único valle principal; por ello, la mayoría de las corridas alcanzaron valores cercanos al mínimo global con menor dispersión. En general se observa que al aumentar la dimensión (de 2D a 3D) la tarea se complica y la media del fitness aumenta (peor óptimo encontrado), reflejando la maldición de la dimensionalidad. El uso de múltiples ejecuciones independientes es esencial para evaluar la robustez de los AG. Debido a su naturaleza estocástica, cada ejecución puede converger a soluciones distintas. Al analizar la media y desviación estándar de los fitness finales se obtiene una medida de fiabilidad del algoritmo: una baja desviación indica resultados consistentes. En la literatura sobre algoritmos genéticos se reconoce que en muchos casos una sola ejecución puede no ser representativa​jstatsoft.org. Aunque un análisis comparativo profundo (p.ej., usando poblaciones más grandes o múltiples corridas en paralelo) queda fuera del alcance de este documento, nuestros resultados ilustran este fenómeno. Este estudio es reproducible: todo el código R necesario está incluido, permitiendo a otros investigadores replicar los experimentos, variar parámetros del GA (tasa de cruce, mutación, tamaño de población, etc.) y comparar con otros algoritmos de optimización.:Conclusiones Se ha presentado una documentación completa de la optimización de las funciones de Rosenbrock y Rastrigin en 2D y 3D empleando algoritmos genéticos en R. Mediante visualizaciones 3D iniciales se ilustraron las características de cada función de prueba. Se implementó el paquete GA para resolver cada caso y se realizaron 30 ejecuciones independientes para evaluar la robustez. Los resultados muestran que el GA puede encontrar aproximaciones al mínimo global en ambos problemas, aunque la función Rastrigin (múltiples mínimos locales) presenta más variabilidad y dificultad, especialmente en 3D.

