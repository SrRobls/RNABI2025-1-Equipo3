{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Módulo 2 - Preprocesado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "###### from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "images_path = kagglehub.dataset_download(\"arafatsahinafridi/multi-class-driver-behavior-image-dataset\") + \"/Multi-Class Driver Behavior Image Dataset\"\n",
    "\n",
    "print(\"Path to dataset files:\", images_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambio de tamaño de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_options = {\n",
    "    \"ResNet\": (224, 224) #(224, 224)\n",
    "}\n",
    "\n",
    "# Modificar esta línea para cambiar la opción de resizing.\n",
    "resize_selection = resize_options[\"ResNet\"]\n",
    "\n",
    "size_transformation = transforms.Resize(resize_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización de valores de pixeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_options = {\n",
    "    \"TorchDefault\": [[0.485, 0.456, 0.406],[0.229, 0.224, 0.225]]\n",
    "}\n",
    "\n",
    "# Modificar esta línea para cambiar la opción de normalización.\n",
    "normalization_option = normalization_options[\"TorchDefault\"]\n",
    "norm_option_mean = normalization_option[0]\n",
    "norm_option_std = normalization_option[1]\n",
    "\n",
    "norm_transformation = transforms.Normalize(mean=norm_option_mean, std=norm_option_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotación aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "randRotation_transformation = transforms.RandomRotation(degrees=(0,180))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotación horizontal aleatoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "randHorizontalRotation_transformation = transforms.RandomHorizontalFlip(p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "toTensor_transformation = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenación de transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_settings = {\n",
    "    \"Initial\": [size_transformation, toTensor_transformation, norm_transformation]\n",
    "}\n",
    "\n",
    "# Modificar para cambiar el pipeline de transformación\n",
    "pipeline_selection = pipeline_settings[\"Initial\"]\n",
    "transform_pipeline = transforms.Compose([\n",
    "    size_transformation,\n",
    "    toTensor_transformation,\n",
    "    norm_transformation\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargado y aplicación de las transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(images_path, transform=transform_pipeline)\n",
    "print(dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Val-Test Split (70%, 20%, 10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_len = len(dataset)\n",
    "train_len = int(0.7 * dataset_len)\n",
    "val_len = int(0.2 * dataset_len)\n",
    "test_len = dataset_len - train_len - val_len\n",
    "\n",
    "train_set, val_set, test_set = random_split(dataset, [train_len, val_len, test_len])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de pérdida y algoritmo de optimización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos[\"Resnet18\"] = {\n",
    "    \"model\": resnet_model,\n",
    "    \"optimizer\": optim.Adam(resnet_model.parameters(), lr=1e-4),\n",
    "    \"criterion\": nn.CrossEntropyLoss()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model = models.vgg19(pretrained=True)\n",
    "vgg19_model.classifier[6] = nn.Linear(4096, 5) # ???, número de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos[\"VGG19\"] = {\n",
    "    \"model\": vgg19_model,\n",
    "    \"optimizer\": optim.Adam(vgg19_model.parameters(), lr=1e-4),\n",
    "    \"criterion\": nn.CrossEntropyLoss()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo custom 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo custom 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración de tracking de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model_name, model): \n",
    "    model_path = f\"./{model_name}.pth\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model {model_name} saved to: {model_path}\")\n",
    "\n",
    "def train_model(model, optimizer, device, criterion, model_name):\n",
    "    # Tracking history1\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 3\n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n Epoch {epoch + 1}/{num_epochs}\")\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = total_train = 0\n",
    "        print(\"Entrenando con imágenes dadas...\")\n",
    "        counter = 1\n",
    "        for images, labels in train_loader:\n",
    "            print(f\"Imagen #{counter}\")\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "            counter += 1\n",
    "        \n",
    "        print(\"Calculando métricas...\")\n",
    "        train_acc = correct_train / total_train\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        # Validation\n",
    "        print(\"Iniciando validación...\")\n",
    "        model.eval()\n",
    "        correct = total = 0\n",
    "        val_loss = 0.0\n",
    "        counter = 1\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                print(f\"Imagen #{counter}\")\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_acc = correct / total\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        counter += 1\n",
    "\n",
    "        print(f\" Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc*100:.2f}%\")\n",
    "        print(f\" Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc*100:.2f}%\")\n",
    "        print(\"\\n\")\n",
    "    save_model(model_name, model)\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies, model\n",
    "\n",
    "\n",
    "# Final test evaluation\n",
    "def test_model(model, device, model_name):\n",
    "    correct = total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    inference_times = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            start_time = time.time()\n",
    "            outputs = model(images)\n",
    "            end_time = time.time()\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            inference_times.append(end_time - start_time)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_probs.extend(probs.cpu())\n",
    "\n",
    "    class_names = [\n",
    "        \"other_actvities\",\n",
    "        \"safe_driving\",\n",
    "        \"talking_phone\",\n",
    "        \"texting_phone\",\n",
    "        \"turning\"\n",
    "    ]\n",
    "    plot_confusion_matrix(all_labels, all_preds, class_names, model_name) \n",
    "\n",
    "    test_acc = correct / total * 100\n",
    "    print(f\"\\n Final Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "    avg_infer_time = np.mean(inference_times)\n",
    "    print(f\"⏱Average Inference Time per Batch: {avg_infer_time:.4f}s\")\n",
    "    print(f\"Average Inference Time per Sample: {avg_infer_time / batch_size:.6f}s\")\n",
    "\n",
    "    # auc= roc_auc_score(all_labels, all_probs, multi_class=\"ovr\")\n",
    "    # print(f\"AUC (multi-class OVR): {auc:.4f}\")\n",
    "    \n",
    "\n",
    "\n",
    "def plot_confusion_matrix(all_labels, all_preds, class_names, model_name):\n",
    "  # Compute confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'Confusion Matrix on Test Set for {model_name}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "  \n",
    "\n",
    "\n",
    "# Plot results\n",
    "def plot_results(train_accuracies, val_accuracies, train_losses, val_losses, num_epochs=10):\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_accuracies, 'o-', label='Train Accuracy')\n",
    "    plt.plot(epochs, val_accuracies, 'o-', label='Val Accuracy')\n",
    "    plt.title('Accuracy vs Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_losses, 'o-', label='Train Loss')\n",
    "    plt.plot(epochs, val_losses, 'o-', label='Val Loss')\n",
    "    plt.title('Loss vs Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model_options in modelos.items():\n",
    "    model = model_options[\"model\"]\n",
    "    optimizer = model_options[\"optimizer\"]\n",
    "    criterion = model_options[\"criterion\"]\n",
    "    device = \"cpu\"\n",
    "    train_losses, val_losses, train_accuracies, val_accuracies, model = train_model(\n",
    "        model,\n",
    "        optimizer,\n",
    "        device,\n",
    "        criterion,\n",
    "        model_name\n",
    "    )\n",
    "    test_model = test_model(model, device, model_name)\n",
    "\n",
    "    plot_results(train_accuracies, val_accuracies, train_losses, val_losses, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones generales"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
