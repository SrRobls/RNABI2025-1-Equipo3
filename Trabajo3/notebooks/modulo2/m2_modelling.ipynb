{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Módulo 2 - Preprocesado y Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/druiz35/Documents/SEpsilon/SEpsilon-Proyectos/AI-ML-Data/RNABI2025-1-Equipo3/Trabajo3/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# === PyTorch y utilidades para deep learning ===\n",
    "import torch  # Librería principal de PyTorch\n",
    "from torchvision import datasets, transforms, models  # Módulos para datasets, transformaciones y modelos preentrenados\n",
    "from torch.utils.data import DataLoader, random_split  # Utilidades para manejo de datos\n",
    "import torch.nn as nn  # Módulo para definir arquitecturas de redes\n",
    "import torch.optim as optim  # Optimizadores como SGD, Adam, etc.\n",
    "\n",
    "# === Visualización ===\n",
    "import matplotlib.pyplot as plt  # Visualización de gráficos y resultados\n",
    "import seaborn as sns  # Visualización estadística\n",
    "\n",
    "# === Utilidades adicionales ===\n",
    "import kagglehub  # Descarga de datasets desde Kaggle Hub\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix  # Métricas de evaluación\n",
    "import time  # Para medir tiempos de ejecución\n",
    "import numpy as np  # Operaciones numéricas\n",
    "from PIL import Image  # Manipulación de imágenes con Pillow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/druiz35/.cache/kagglehub/datasets/arafatsahinafridi/multi-class-driver-behavior-image-dataset/versions/1/Multi-Class Driver Behavior Image Dataset\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "images_path = kagglehub.dataset_download(\"arafatsahinafridi/multi-class-driver-behavior-image-dataset\") + \"/Multi-Class Driver Behavior Image Dataset\"\n",
    "\n",
    "print(\"Path to dataset files:\", images_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambio de tamaño de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define las dimensiones de redimensionado que se usarán para las imágenes según el modelo seleccionado\n",
    "resize_options = {\n",
    "    \"ResNet\": (224, 224)  # Tamaño requerido por modelos tipo ResNet preentrenados\n",
    "}\n",
    "\n",
    "# Selección del tamaño de redimensionado (puede cambiarse según el modelo a utilizar)\n",
    "resize_selection = resize_options[\"ResNet\"]\n",
    "\n",
    "# Transformación de redimensionado a aplicar a las imágenes\n",
    "size_transformation = transforms.Resize(resize_selection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización de valores de pixeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define los parámetros de normalización según los valores utilizados en modelos preentrenados de PyTorch\n",
    "normalization_options = {\n",
    "    \"TorchDefault\": [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]  # Media y desviación estándar por canal (RGB)\n",
    "}\n",
    "\n",
    "# Selección del esquema de normalización (ajustable)\n",
    "normalization_option = normalization_options[\"TorchDefault\"]\n",
    "norm_option_mean = normalization_option[0]\n",
    "norm_option_std = normalization_option[1]\n",
    "\n",
    "# Transformación de normalización a aplicar a las imágenes\n",
    "norm_transformation = transforms.Normalize(mean=norm_option_mean, std=norm_option_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotación aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación de aumento de datos: aplica una rotación aleatoria entre 0° y 180°\n",
    "randRotation_transformation = transforms.RandomRotation(degrees=(0, 180))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotación horizontal aleatoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación de aumento de datos: aplica una inversión horizontal con probabilidad del 50%\n",
    "randHorizontalRotation_transformation = transforms.RandomHorizontalFlip(p=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación que convierte una imagen PIL o NumPy array en un tensor de PyTorch y escala los valores a [0, 1]\n",
    "toTensor_transformation = transforms.ToTensor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenación de transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y selecciona un pipeline de transformaciones a aplicar a las imágenes\n",
    "pipeline_settings = {\n",
    "    \"Initial\": [size_transformation, toTensor_transformation, norm_transformation]\n",
    "}\n",
    "\n",
    "# Selección del pipeline de transformación (puede modificarse para pruebas o entrenamiento)\n",
    "pipeline_selection = pipeline_settings[\"Initial\"]\n",
    "\n",
    "# Composición final de las transformaciones a aplicar en secuencia\n",
    "transform_pipeline = transforms.Compose([\n",
    "    size_transformation,\n",
    "    toTensor_transformation,\n",
    "    norm_transformation\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargado y aplicación de las transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['other_activities', 'safe_driving', 'talking_phone', 'texting_phone', 'turning']\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.ImageFolder(images_path, transform=transform_pipeline)\n",
    "class_to_idx = dataset.class_to_idx  # e.g., {'safe_driving': 0, 'texting_phone': 1, ...}\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}  # e.g., {0: 'safe_driving', ...}\n",
    "print(idx_to_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Val-Test Split (70%, 20%, 10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide el dataset en subconjuntos de entrenamiento (70%), validación (20%) y prueba (10%)\n",
    "dataset_len = len(dataset)\n",
    "train_len = int(0.7 * dataset_len)\n",
    "val_len = int(0.2 * dataset_len)\n",
    "test_len = dataset_len - train_len - val_len  # Asegura que la suma sea igual al total\n",
    "\n",
    "train_set, val_set, test_set = random_split(dataset, [train_len, val_len, test_len])\n",
    "\n",
    "# Crea los dataloaders para cada subconjunto, con batch size de 32\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True  # Mezcla aleatoriamente los datos en cada época (solo para entrenamiento)\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False  # Sin mezcla para mantener consistencia en validación\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False  # Sin mezcla para evaluación final\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de pérdida y algoritmo de optimización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario para ir guardando los modelos a probar\n",
    "modelos = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/druiz35/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/druiz35/Documents/SEpsilon/SEpsilon-Proyectos/AI-ML-Data/RNABI2025-1-Equipo3/Trabajo3/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/druiz35/Documents/SEpsilon/SEpsilon-Proyectos/AI-ML-Data/RNABI2025-1-Equipo3/Trabajo3/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Carga el modelo ResNet-18 preentrenado en ImageNet desde PyTorch Hub\n",
    "resnet_model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura el modelo ResNet-18 dentro del dict de modelos con su optimizador y función de pérdida\n",
    "modelos[\"Resnet18\"] = {\n",
    "    \"model\": resnet_model,\n",
    "    \"optimizer\": optim.Adam(resnet_model.parameters(), lr=1e-4),  # Optimizador Adam con tasa de aprendizaje 1e-4\n",
    "    \"criterion\": nn.CrossEntropyLoss()  # Función de pérdida para clasificación multiclase\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/druiz35/Documents/SEpsilon/SEpsilon-Proyectos/AI-ML-Data/RNABI2025-1-Equipo3/Trabajo3/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Carga el modelo VGG19 preentrenado y ajusta la última capa del clasificador para adaptarse a 5 clases\n",
    "vgg19_model = models.vgg19(pretrained=True)\n",
    "vgg19_model.classifier[6] = nn.Linear(4096, 5)  # Reemplaza la capa final para clasificación en 5 clases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura el modelo VGG19 con su optimizador y función de pérdida, y lo agrega al diccionario de modelos\n",
    "modelos[\"VGG19\"] = {\n",
    "    \"model\": vgg19_model,\n",
    "    \"optimizer\": optim.Adam(vgg19_model.parameters(), lr=1e-4),  # Optimizador Adam con learning rate de 1e-4\n",
    "    \"criterion\": nn.CrossEntropyLoss()  # Función de pérdida para clasificación multiclase\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de una red neuronal convolucional personalizada (CNNAlpha) para clasificación en 6 clases\n",
    "class CNNAlpha(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # Reduce a la mitad las dimensiones espaciales\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 28 * 28, 1024),  # Asume entrada redimensionada a 224x224\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 5)  # Capa final con salida para 5 clases\n",
    "        )\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia el modelo CNNAlpha y lo agrega al diccionario de modelos junto con su optimizador y función de pérdida\n",
    "cnnalpha = CNNAlpha()\n",
    "modelos[\"CNNAlpha\"] = {\n",
    "    \"model\": cnnalpha,\n",
    "    \"optimizer\": optim.Adam(cnnalpha.parameters(), lr=1e-4),  # Optimizador Adam con tasa de aprendizaje 1e-4\n",
    "    \"criterion\": nn.CrossEntropyLoss()  # Función de pérdida para clasificación multiclase\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración de tracking de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Función para guardar el modelo entrenado en disco ===\n",
    "def save_model(model_name, model): \n",
    "    model_path = f\"./{model_name}.pth\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model {model_name} saved to: {model_path}\")\n",
    "\n",
    "# === Función de entrenamiento y validación del modelo ===\n",
    "def train_model(model, optimizer, device, criterion, model_name):\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    num_epochs = 6  # Número de épocas de entrenamiento\n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n Epoch {epoch + 1}/{num_epochs}\")\n",
    "        \n",
    "        # --- Entrenamiento ---\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = total_train = 0\n",
    "        print(\"Entrenando con imágenes dadas...\")\n",
    "        counter = 1\n",
    "        for images, labels in train_loader:\n",
    "            print(f\"Imagen #{counter}\")\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "            counter += 1\n",
    "        \n",
    "        # Métricas de entrenamiento\n",
    "        print(\"Calculando métricas...\")\n",
    "        train_acc = correct_train / total_train\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        # --- Validación ---\n",
    "        print(\"Iniciando validación...\")\n",
    "        model.eval()\n",
    "        correct = total = 0\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            counter = 1\n",
    "            for images, labels in val_loader:\n",
    "                print(f\"Imagen #{counter}\")\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                counter += 1\n",
    "\n",
    "        # Métricas de validación\n",
    "        val_acc = correct / total\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f\" Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc*100:.2f}%\")\n",
    "        print(f\" Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc*100:.2f}%\\n\")\n",
    "    \n",
    "    # Guarda el modelo entrenado\n",
    "    save_model(model_name, model)\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies, model\n",
    "\n",
    "# === Evaluación final en el set de prueba ===\n",
    "def test_model(model, device, model_name):\n",
    "    correct = total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    inference_times = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            start_time = time.time()\n",
    "            outputs = model(images)\n",
    "            end_time = time.time()\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            inference_times.append(end_time - start_time)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu())\n",
    "\n",
    "    # Metrics\n",
    "    test_acc = accuracy_score(all_labels, all_preds)\n",
    "    test_precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    test_recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    test_f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    print(f\"\\nFinal Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "    print(f\"Precision (weighted): {test_precision:.4f}\")\n",
    "    print(f\"Recall (weighted): {test_recall:.4f}\")\n",
    "    print(f\"F1-score (weighted): {test_f1:.4f}\")\n",
    "\n",
    "    avg_infer_time = np.mean(inference_times)\n",
    "    print(f\"\\nAverage Inference Time per Batch: {avg_infer_time:.4f}s\")\n",
    "    print(f\"Average Inference Time per Sample: {avg_infer_time / batch_size:.6f}s\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    class_names = [idx_to_class[i] for i in range(len(idx_to_class))]\n",
    "    plot_confusion_matrix(all_labels, all_preds, class_names, model_name)\n",
    "\n",
    "\n",
    "# === Visualización de la matriz de confusión ===\n",
    "def plot_confusion_matrix(all_labels, all_preds, class_names, model_name):\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'Confusion Matrix on Test Set for {model_name}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Visualización de los resultados de entrenamiento ===\n",
    "def plot_results(train_accuracies, val_accuracies, train_losses, val_losses, num_epochs=10):\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    # Gráfico de precisión\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_accuracies, 'o-', label='Train Accuracy')\n",
    "    plt.plot(epochs, val_accuracies, 'o-', label='Val Accuracy')\n",
    "    plt.title('Accuracy vs Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Gráfico de pérdida\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_losses, 'o-', label='Train Loss')\n",
    "    plt.plot(epochs, val_losses, 'o-', label='Val Loss')\n",
    "    plt.title('Loss vs Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento, Validación y Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRENAMIENTO DE MODELO: CNNAlpha\n",
      "Starting training...\n",
      "\n",
      " Epoch 1/3\n",
      "Entrenando con imágenes dadas...\n",
      "Imagen #1\n",
      "Imagen #2\n",
      "Imagen #3\n",
      "Imagen #4\n",
      "Imagen #5\n",
      "Imagen #6\n",
      "Imagen #7\n",
      "Imagen #8\n",
      "Imagen #9\n",
      "Imagen #10\n",
      "Imagen #11\n",
      "Imagen #12\n",
      "Imagen #13\n",
      "Imagen #14\n",
      "Imagen #15\n",
      "Imagen #16\n",
      "Imagen #17\n",
      "Imagen #18\n",
      "Imagen #19\n",
      "Imagen #20\n",
      "Imagen #21\n",
      "Imagen #22\n",
      "Imagen #23\n",
      "Imagen #24\n",
      "Imagen #25\n",
      "Imagen #26\n",
      "Imagen #27\n",
      "Imagen #28\n",
      "Imagen #29\n",
      "Imagen #30\n",
      "Imagen #31\n",
      "Imagen #32\n",
      "Imagen #33\n",
      "Imagen #34\n",
      "Imagen #35\n",
      "Imagen #36\n",
      "Imagen #37\n",
      "Imagen #38\n",
      "Imagen #39\n",
      "Imagen #40\n",
      "Imagen #41\n",
      "Imagen #42\n",
      "Imagen #43\n",
      "Imagen #44\n"
     ]
    }
   ],
   "source": [
    "#del modelos[\"Resnet18\"] # HOTFIX!!! COMENTAR SI NO SE HA ENTRENADO ESTE MODELO. \n",
    "#del modelos[\"VGG19\"]\n",
    "\n",
    "# Entrena y evalúa cada modelo definido en el diccionario 'modelos'\n",
    "\"\"\"\n",
    "for model_name, model_options in modelos.items():\n",
    "    print(f\"ENTRENAMIENTO DE MODELO: {model_name}\")\n",
    "    \n",
    "    # Extrae modelo, optimizador y función de pérdida\n",
    "    model = model_options[\"model\"]\n",
    "    optimizer = model_options[\"optimizer\"]\n",
    "    criterion = model_options[\"criterion\"]\n",
    "    device = \"cpu\"  # Se puede cambiar a \"cuda\" si hay GPU disponible\n",
    "\n",
    "    # Entrenamiento del modelo\n",
    "    train_losses, val_losses, train_accuracies, val_accuracies, model = train_model(\n",
    "        model,\n",
    "        optimizer,\n",
    "        device,\n",
    "        criterion,\n",
    "        model_name\n",
    "    )\n",
    "\n",
    "    # Evaluación final sobre el conjunto de prueba\n",
    "    test_model(model, device, model_name)\n",
    "\n",
    "    #plot_results(train_accuracies, val_accuracies, train_losses, val_losses, num_epochs=10)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga modelos\n",
    "resnet_path = \"./Resnet18.pth\"\n",
    "vgg_path = \"./VGG19.pth\"\n",
    "cnnalpha_path = \"CNNAlpha.pth\" \n",
    "\n",
    "modelos = {}\n",
    "resnet = models.resnet18()\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, 5)\n",
    "resnet.load_state_dict(torch.load(resnet_path))\n",
    "resnet.eval()\n",
    "modelos[\"ResNet18\"] = resnet\n",
    "\n",
    "vgg = models.vgg19()\n",
    "vgg.classifier[6] = nn.Linear(4096, 5)\n",
    "vgg.load_state_dict(torch.load(vgg_path))\n",
    "vgg.eval()\n",
    "modelos[\"VGG19\"] = vgg\n",
    "\n",
    "cnnalpha = CNNAlpha()\n",
    "cnnalpha.load_state_dict(torch.load(cnnalpha_path))\n",
    "cnnalpha.eval()\n",
    "modelos[\"CNNAlpha\"] = cnnalpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model_name, model in modelos.items():\n",
    "    print(f\"TESTING DE MODELO: {model_name}\")\n",
    "    \n",
    "    device = \"cpu\"  # Se puede cambiar a \"cuda\" si hay GPU disponible\n",
    "    # Evaluación final sobre el conjunto de prueba\n",
    "    test_model(model, device, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones generales"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
