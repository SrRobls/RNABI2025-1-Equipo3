# -*- coding: utf-8 -*-
"""modulo1_completo.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HW06JJKClvhYNV5lFV48MevX6U8799LV
"""

# modulo1_completo.py
# Módulo 1: Predicción de Demanda de Transporte
# Genera predicciones de demanda usando modelos simples para cada destino.
# Entrada: horizon_days (días a predecir, por defecto 30).
# Salida: dict con resultados por ruta.
# Requiere: Final_Updated_Expanded_UserHistory.csv, Expanded_Destinations.csv en ./notebooks/modulo1/.

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.linear_model import LinearRegression
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.arima.model import ARIMA
import warnings

warnings.filterwarnings("ignore")

def run_module1(horizon_days: int = 30) -> dict:
    """
    Forecast simple usando ARIMA/Linear Regression por destino. 
    Input: horizon_days (int).
    Lee Final_Updated_Expanded_UserHistory.csv y Expanded_Destinations.csv
    en el directorio notebooks/modulo1/.
    Output: dict con clave=ruta y valor={
        metrics: {RMSE, MAE, R2},
        forecast_df: DataFrame completo,
        fig_demand: Figura demanda sintética,
        fig_decomp: Figura descomposición
    }
    """
    base = os.path.dirname(__file__)
    history_csv = os.path.join(base, "Final_Updated_Expanded_UserHistory.csv")
    dest_csv = os.path.join(base, "Expanded_Destinations.csv")

    try:
        # 1) Leer datos
        user_hist = pd.read_csv(history_csv, parse_dates=["VisitDate"])
        dests = pd.read_csv(dest_csv)
        name_map = dests.set_index("DestinationID")["Name"].to_dict()
    except FileNotFoundError as e:
        print(f"Error: No se pudo encontrar el archivo: {e}")
        return {}

    # 2) Pivot diario de trips
    trips = (
        user_hist
        .groupby(["VisitDate", "DestinationID"])
        .size()
        .reset_index(name="Trips")
    )
    idx = pd.date_range(trips["VisitDate"].min(),
                        trips["VisitDate"].max(),
                        freq="D")
    pivot = (
        trips
        .pivot(index="VisitDate", columns="DestinationID", values="Trips")
        .reindex(idx, fill_value=0)
    )
    pivot.index.name = "ds"
    pivot.columns = [
        f"{name_map.get(i,i)}_{i}" for i in pivot.columns
    ]

    results = {}
    
    # 3) Por cada destino (limitado a 5 para pruebas)
    for ruta in pivot.columns[:5]:
        df_ts = pivot[[ruta]].reset_index().rename(columns={ruta: "y"})
        if len(df_ts) <= 10:  # Necesitamos al menos 10 puntos
            print(f"Ruta {ruta} omitida: datos insuficientes.")
            continue

        try:
            # 4) Preparar datos para forecasting simple
            ts_data = df_ts["y"].values
            
            # 5) Modelo simple de tendencia lineal
            X = np.arange(len(ts_data)).reshape(-1, 1)
            y = ts_data
            
            # Entrenar modelo lineal simple
            model = LinearRegression()
            model.fit(X, y)
            
            # 6) Generar forecast
            future_X = np.arange(len(ts_data), len(ts_data) + horizon_days).reshape(-1, 1)
            future_preds = model.predict(future_X)
            
            # Asegurar que las predicciones no sean negativas
            future_preds = np.maximum(future_preds, 0)
            
            # 7) Construir DataFrame histórico + pronóstico
            fut_idx = pd.date_range(
                df_ts["ds"].iloc[-1] + pd.Timedelta(days=1),
                periods=horizon_days,
                freq="D"
            )
            df_fc = pd.DataFrame({
                "ds": np.concatenate([df_ts["ds"].values, fut_idx]),
                "y": np.concatenate([ts_data, future_preds])
            })

            # 8) Métricas back-test simples
            n = len(df_ts)
            if n >= horizon_days:
                # Usar últimos días para validación
                split_point = n - min(horizon_days, 7)  # máximo 7 días para test
                train_data = ts_data[:split_point]
                test_data = ts_data[split_point:]
                
                # Entrenar en datos de entrenamiento
                X_train = np.arange(len(train_data)).reshape(-1, 1)
                model_test = LinearRegression()
                model_test.fit(X_train, train_data)
                
                # Predecir en datos de prueba
                X_test = np.arange(len(train_data), len(train_data) + len(test_data)).reshape(-1, 1)
                test_preds = model_test.predict(X_test)
                test_preds = np.maximum(test_preds, 0)
                
                # Calcular métricas
                rmse = np.sqrt(mean_squared_error(test_data, test_preds))
                mae = mean_absolute_error(test_data, test_preds)
                
                # R² simple
                ss_res = np.sum((test_data - test_preds) ** 2)
                ss_tot = np.sum((test_data - np.mean(test_data)) ** 2)
                r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0
            else:
                rmse, mae, r2 = 0, 0, 0

            # 9) Figuras
            fig_demand, ax1 = plt.subplots(figsize=(12, 6))
            hist_len = len(df_ts)
            
            # Histórico
            ax1.plot(df_fc["ds"][:hist_len], df_fc["y"][:hist_len], 
                    label="Histórico", color="blue", linewidth=2)
            # Pronóstico
            ax1.plot(df_fc["ds"][hist_len-1:], df_fc["y"][hist_len-1:], 
                    label="Pronóstico", color="red", linestyle="--", linewidth=2)
            
            ax1.set_title(f"Demanda de {ruta}")
            ax1.set_xlabel("Fecha")
            ax1.set_ylabel("Número de viajes")
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            # Rotar labels de fecha
            import matplotlib.dates as mdates
            ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
            ax1.xaxis.set_major_locator(mdates.DayLocator(interval=max(1, len(df_fc)//10)))
            plt.xticks(rotation=45)
            plt.tight_layout()

            # 10) Descomposición (si hay suficientes datos)
            fig_decomp = None
            try:
                if len(df_ts) > 14:  # Necesitamos suficientes datos
                    # Crear serie temporal con frecuencia diaria
                    ts_series = pd.Series(df_ts["y"].values, index=pd.to_datetime(df_ts["ds"]))
                    ts_series.index.freq = 'D'
                    
                    decomposition = seasonal_decompose(ts_series, model='additive', period=7)  # Periodo semanal
                    
                    fig_decomp, axes = plt.subplots(4, 1, figsize=(12, 10))
                    decomposition.observed.plot(ax=axes[0], title="Serie Original")
                    decomposition.trend.plot(ax=axes[1], title="Tendencia")
                    decomposition.seasonal.plot(ax=axes[2], title="Estacionalidad")
                    decomposition.resid.plot(ax=axes[3], title="Residuos")
                    
                    plt.tight_layout()
            except Exception as e:
                print(f"No se pudo generar descomposición para {ruta}: {e}")

            results[ruta] = {
                "metrics": {"RMSE": rmse, "MAE": mae, "R2": r2},
                "forecast_df": df_fc,
                "fig_demand": fig_demand,
                "fig_decomp": fig_decomp
            }

        except Exception as e:
            print(f"Error procesando ruta {ruta}: {e}")
            continue

    return results

if __name__ == "__main__":
    results = run_module1(horizon_days=30)