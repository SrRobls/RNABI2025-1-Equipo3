# üöÄ Gu√≠a de Deployment Optimizado

## Problema Identificado

El error `no space left on device` se debe a que PyTorch (`torch`) es una librer√≠a muy pesada, especialmente el archivo `libtorch_cpu.so` que puede ocupar varios GB durante el proceso de build.

## ‚úÖ Soluciones Implementadas

### 1. **Requirements Optimizado**
- `requirements-deployment.txt`: Versi√≥n ligera solo para producci√≥n
- Usa versiones CPU-only de PyTorch: `torch==2.1.0+cpu`
- Elimina dependencias innecesarias

### 2. **Dockerfile Optimizado**
- Imagen base `python:3.9-slim` (m√°s ligera)
- Multi-stage build para reducir tama√±o final
- Cache de dependencias optimizado
- Flag `--no-cache-dir` para pip

### 3. **.dockerignore Configurado**
- Excluye archivos grandes innecesarios
- No incluye notebooks pesados ni datasets
- Mantiene solo archivos esenciales

## üîß Pasos para Deployment

### Opci√≥n A: Deployment R√°pido
```bash
# 1. Usar script automatizado
./deploy.sh

# 2. Ir al directorio optimizado
cd deploy_temp

# 3. Deployar con el requirements optimizado
# Renombrar requirements-deployment.txt a requirements.txt
mv requirements-deployment.txt requirements.txt
```

### Opci√≥n B: Deployment Manual
```bash
# 1. Crear directorio limpio
mkdir deployment
cd deployment

# 2. Copiar solo archivos esenciales
cp ../app.py .
cp ../requirements-deployment.txt requirements.txt
cp ../Dockerfile .
cp -r ../notebooks/modulo2/ notebooks/

# 3. Limpiar archivos grandes
rm -f notebooks/modulo2/*.ipynb
rm -f notebooks/modulo2/image_set_*.png
```

## üìä Optimizaciones Adicionales

### 1. **Reducir Tama√±o del Modelo**
Si el modelo sigue siendo muy grande, considera:

```python
# Cuantizaci√≥n del modelo (en un script separado)
import torch

# Cargar modelo
model = torch.load('Resnet18.pth', map_location='cpu')

# Cuantizar a int8
model_quantized = torch.quantization.quantize_dynamic(
    model, {torch.nn.Linear}, dtype=torch.qint8
)

# Guardar modelo cuantizado
torch.save(model_quantized.state_dict(), 'Resnet18_quantized.pth')
```

### 2. **Variables de Entorno para DigitalOcean**
```bash
# Limitar uso de memoria durante build
export PYTORCH_BUILD_NUMBER=0
export MAX_JOBS=1
```

### 3. **Alternativa: Usar CPU-only desde el inicio**
```txt
# requirements-minimal.txt
streamlit==1.28.1
torch==2.1.0+cpu --find-links https://download.pytorch.org/whl/torch_stable.html
torchvision==0.16.0+cpu --find-links https://download.pytorch.org/whl/torch_stable.html
Pillow==9.5.0
numpy==1.24.4
```

## üÜò Soluciones de Emergencia

### Si el problema persiste:

1. **Aumentar el plan de DigitalOcean temporalmente**
   - Upgrade a un droplet con m√°s espacio
   - Hacer el deployment
   - Downgrade despu√©s del deployment exitoso

2. **Usar un modelo pre-compilado m√°s peque√±o**
   - Buscar versiones optimizadas del modelo
   - Usar TorchScript para optimizar

3. **Deployment en dos fases**
   ```bash
   # Fase 1: Solo dependencias
   pip install streamlit pandas numpy Pillow
   
   # Fase 2: PyTorch optimizado
   pip install torch==2.1.0+cpu torchvision==0.16.0+cpu -f https://download.pytorch.org/whl/torch_stable.html
   ```

## üìà Verificaci√≥n del Deployment

1. **Comprobar tama√±o del contenedor**
   ```bash
   docker images | grep your-app-name
   ```

2. **Verificar funcionamiento**
   ```bash
   curl http://localhost:8501/_stcore/health
   ```

3. **Monitorear uso de recursos**
   ```bash
   docker stats your-container-name
   ```

## üéØ Resultados Esperados

Con estas optimizaciones deber√≠as conseguir:
- ‚¨áÔ∏è **Reducci√≥n del 60-70%** en tama√±o del contenedor
- ‚ö° **Build 3x m√°s r√°pido**
- üíæ **Menor uso de espacio en disco**
- ‚úÖ **Deployment exitoso en DigitalOcean**

---

**üí° Tip**: Si nada funciona, considera usar un servicio como Hugging Face Spaces o Streamlit Cloud que est√°n optimizados para aplicaciones ML. 